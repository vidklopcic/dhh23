{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T07:19:22.627887Z",
     "start_time": "2023-05-30T07:19:22.135394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import stopwordsiso as stopwords\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Languages:\n",
    "    si = 'SI'\n",
    "    gb = 'GB'\n",
    "    hu = 'HU'\n",
    "    ua = 'UA'\n",
    "    all = [si, gb, hu, ua]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T07:19:25.315674Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading SI\n"
     ]
    }
   ],
   "source": [
    "sentences = {}\n",
    "for language in Languages.all:\n",
    "    print('loading', language)\n",
    "    sentences[language] = pd.read_feather(f'artefacts/pandas_frames/{language}_parlamint_sentences.feather')\n",
    "metadata = pd.read_feather('artefacts/pandas_frames/parlamint_metadata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T11:54:43.712725Z",
     "start_time": "2023-05-29T11:54:26.026902Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.45s/it]\n"
     ]
    }
   ],
   "source": [
    "artefacts_pd_frames = Path('artefacts/pandas_frames')\n",
    "speeches = {}\n",
    "for language in tqdm(sentences):\n",
    "    with open(artefacts_pd_frames / f'speech2lemmas_{language}.pkl', 'rb') as f:\n",
    "        speeches[language] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T12:35:15.380984Z",
     "start_time": "2023-05-29T12:34:20.549643Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading SI len = 311354\n",
      "loading UA len = 195685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_643588/306785991.py:11: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lang_df = pd.read_csv(artefacts_base / csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading HU len = 104521\n",
      "loading GB len = 472782\n"
     ]
    }
   ],
   "source": [
    "artefacts_base = Path('artefacts/bojan')\n",
    "files = {\n",
    "    Languages.si: 'ParlaMint-SI_with_sentiment.csv',\n",
    "    Languages.ua: 'ParlaMint-UA_with_sentiment.csv',\n",
    "    Languages.hu: 'ParlaMint-HU_with_sentiment.csv',\n",
    "    Languages.gb: 'ParlaMint-GB-commons_with_sentiment.csv',\n",
    "}\n",
    "filtered_speeches = {}\n",
    "filtered_speech_ids = set()\n",
    "for language, csv_file in files.items():\n",
    "    lang_df = pd.read_csv(artefacts_base / csv_file)\n",
    "    print('loaded', language, 'len =', len(lang_df))\n",
    "    lang_df = lang_df[lang_df['Speaker_role'] == 'Regular']\n",
    "    lang_df = lang_df[lang_df['Speaker_MP'] == 'MP']\n",
    "    lang_df['speech_length'] = lang_df['speech'].apply(lambda x: len(x) if type(x) == str else 0)\n",
    "    lang_df = lang_df[lang_df['speech_length'] > 200]\n",
    "    filtered_speech_ids.update(lang_df.ID)\n",
    "    filtered_speeches[language] = lang_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T07:03:36.161178Z",
     "start_time": "2023-05-30T07:03:36.090819Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_speech_ids(speech2lemmas: dict[str, set[str]], keywords: set[str]):\n",
    "    for speech_id, lemmas in speech2lemmas.items():\n",
    "        speech_id = speech_id.replace('.ana', '')\n",
    "        if speech_id not in filtered_speech_ids:\n",
    "            continue\n",
    "        lemmas = f' {lemmas.lower()} '\n",
    "        for keyword in keywords:\n",
    "            if f' {keyword} ' in lemmas:\n",
    "                yield speech_id\n",
    "                break\n",
    "\n",
    "\n",
    "def get_corpuses(topic_by_language: dict[str, set[str]]):\n",
    "    corpuses = {}\n",
    "    for language, speech2lemmas in speeches.items():\n",
    "        speech_ids = list(get_speech_ids(speech2lemmas, topic_by_language[language]))\n",
    "        corpuses[language] = speech_ids\n",
    "    return corpuses\n",
    "\n",
    "\n",
    "def print_corpuses(corpuses):\n",
    "    for lang, corpus in corpuses.items():\n",
    "        print(f'{lang}:', len(corpus))\n",
    "        print(corpus[:10])\n",
    "        print('-' * 40)\n",
    "\n",
    "\n",
    "def save_corpuses(topic, corpuses):\n",
    "    artefacts_dir = Path('artefacts/by_topic')\n",
    "    artefacts_dir.mkdir(exist_ok=True)\n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'common': set([t for l in corpuses.values() for t in l]),\n",
    "        **corpuses\n",
    "    }, orient='index').transpose()\n",
    "    df.to_feather(artefacts_dir / f'{topic}.feather')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T07:00:05.984528Z",
     "start_time": "2023-05-30T07:00:05.109647Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eu', 'war', 'healthcare', 'gender'])\n",
      "dict_keys(['UK', 'Hungary', 'Slovenian', 'Ukrainian'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://docs.google.com/spreadsheets/d/1v7Kv1kVPWhBwGMDI6g2-pfanTfKuys8mmp1L0sMsMsM/export?format=csv&gid=0'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "topics = {}\n",
    "for column in df.columns:\n",
    "    if '_tr' in column:\n",
    "        continue\n",
    "    theme, lang = column.split(' (')\n",
    "    theme = theme.split(': ')[1].lower()\n",
    "    lang = lang.rstrip(')')\n",
    "    if theme not in topics:\n",
    "        topics[theme] = {}\n",
    "    topics[theme][lang] = [i.lower() for i in df[column].tolist() if type(i) is str and i]\n",
    "\n",
    "print(topics.keys())\n",
    "print(topics['healthcare'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T07:01:38.489395Z",
     "start_time": "2023-05-30T07:00:07.638366Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:30<00:00, 22.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>SI_count</th>\n",
       "      <th>SI_percentage</th>\n",
       "      <th>GB_count</th>\n",
       "      <th>GB_percentage</th>\n",
       "      <th>HU_count</th>\n",
       "      <th>HU_percentage</th>\n",
       "      <th>UA_count</th>\n",
       "      <th>UA_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu</td>\n",
       "      <td>5138</td>\n",
       "      <td>4.159314</td>\n",
       "      <td>12338</td>\n",
       "      <td>3.250589</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.058630</td>\n",
       "      <td>1113</td>\n",
       "      <td>1.587392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>war</td>\n",
       "      <td>3545</td>\n",
       "      <td>2.869748</td>\n",
       "      <td>2978</td>\n",
       "      <td>0.784589</td>\n",
       "      <td>730</td>\n",
       "      <td>1.718860</td>\n",
       "      <td>1670</td>\n",
       "      <td>2.381801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>healthcare</td>\n",
       "      <td>7726</td>\n",
       "      <td>6.254351</td>\n",
       "      <td>16214</td>\n",
       "      <td>4.271766</td>\n",
       "      <td>1536</td>\n",
       "      <td>3.616671</td>\n",
       "      <td>1599</td>\n",
       "      <td>2.280539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender</td>\n",
       "      <td>373</td>\n",
       "      <td>0.301951</td>\n",
       "      <td>1228</td>\n",
       "      <td>0.323531</td>\n",
       "      <td>8</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>8</td>\n",
       "      <td>0.011410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic  SI_count  SI_percentage  GB_count  GB_percentage  HU_count  \\\n",
       "0          eu      5138       4.159314     12338       3.250589      1299   \n",
       "1         war      3545       2.869748      2978       0.784589       730   \n",
       "2  healthcare      7726       6.254351     16214       4.271766      1536   \n",
       "3      gender       373       0.301951      1228       0.323531         8   \n",
       "\n",
       "   HU_percentage  UA_count  UA_percentage  \n",
       "0       3.058630      1113       1.587392  \n",
       "1       1.718860      1670       2.381801  \n",
       "2       3.616671      1599       2.280539  \n",
       "3       0.018837         8       0.011410  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = []\n",
    "languages = {\n",
    "    'UK': Languages.gb,\n",
    "    'Hungary': Languages.hu,\n",
    "    'Slovenian': Languages.si,\n",
    "    'Ukrainian': Languages.ua,\n",
    "}\n",
    "topic_dfs = {}\n",
    "for topic in tqdm(topics):\n",
    "    row_dict = {'topic': topic}\n",
    "    keywords = {}\n",
    "    for language in topics[topic]:\n",
    "        keywords[languages[language]] = set(topics[topic][language])\n",
    "    topic_df = save_corpuses(topic, get_corpuses(keywords))\n",
    "    topic_dfs[topic] = topic_df\n",
    "    topic_df_count = topic_df.count().to_dict()\n",
    "    for lang, count in topic_df_count.items():\n",
    "        if lang not in Languages.all:\n",
    "            continue\n",
    "        percentage = 100 * count / len(filtered_speeches[lang])\n",
    "        row_dict[f'{lang}_count'] = count\n",
    "        row_dict[f'{lang}_percentage'] = percentage\n",
    "    df_data.append(row_dict)\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T07:16:28.185137Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(topics):\n\u001b[1;32m      2\u001b[0m     topic_df \u001b[38;5;241m=\u001b[39m topic_dfs[topic]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m language, language_speeches \u001b[38;5;129;01min\u001b[39;00m filtered_speeches\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "for topic in tqdm(topics):\n",
    "    topic_df = topic_dfs[topic]\n",
    "    for language, language_speeches in filtered_speeches.items():\n",
    "        language_speeches[language_speeches.ID.isin(topic_df.common)].reset_index(drop=True).to_csv(f'artefacts/by_topic/topic_csvs/{topic}_{language}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
