{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T11:52:57.512317Z",
     "start_time": "2023-05-29T11:52:57.449572Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import stopwordsiso as stopwords\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Languages:\n",
    "    si = 'SI'\n",
    "    gb = 'GB'\n",
    "    hu = 'HU'\n",
    "    ua = 'UA'\n",
    "    all = [si, gb, hu, ua]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T11:53:43.366091Z",
     "start_time": "2023-05-29T11:53:08.788813Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading SI\n",
      "loading GB\n",
      "loading HU\n",
      "loading UA\n"
     ]
    }
   ],
   "source": [
    "sentences = {}\n",
    "for language in Languages.all:\n",
    "    print('loading', language)\n",
    "    sentences[language] = pd.read_feather(f'artefacts/pandas_frames/{language}_parlamint_sentences.feather')\n",
    "metadata = pd.read_feather('artefacts/pandas_frames/parlamint_metadata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T11:54:43.712725Z",
     "start_time": "2023-05-29T11:54:26.026902Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.45s/it]\n"
     ]
    }
   ],
   "source": [
    "artefacts_pd_frames = Path('artefacts/pandas_frames')\n",
    "speeches = {}\n",
    "for language in tqdm(sentences):\n",
    "    with open(artefacts_pd_frames / f'speech2lemmas_{language}.pkl', 'rb') as f:\n",
    "        speeches[language] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T12:35:15.380984Z",
     "start_time": "2023-05-29T12:34:20.549643Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading SI len = 311354\n",
      "loading UA len = 195685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_643588/306785991.py:11: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lang_df = pd.read_csv(artefacts_base / csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading HU len = 104521\n",
      "loading GB len = 472782\n"
     ]
    }
   ],
   "source": [
    "artefacts_base = Path('artefacts/bojan')\n",
    "files = {\n",
    "    Languages.si: 'ParlaMint-SI_with_sentiment.csv',\n",
    "    Languages.ua: 'ParlaMint-UA_with_sentiment.csv',\n",
    "    Languages.hu: 'ParlaMint-HU_with_sentiment.csv',\n",
    "    Languages.gb: 'ParlaMint-GB-commons_with_sentiment.csv',\n",
    "}\n",
    "filtered_speeches = {}\n",
    "filtered_speech_ids = set()\n",
    "for language, csv_file in files.items():\n",
    "    lang_df = pd.read_csv(artefacts_base / csv_file)\n",
    "    print('loaded', language, 'len =', len(lang_df))\n",
    "    lang_df = lang_df[lang_df['Speaker_role'] == 'Regular']\n",
    "    lang_df = lang_df[lang_df['Speaker_MP'] == 'MP']\n",
    "    lang_df['speech_length'] = lang_df['speech'].apply(lambda x: len(x) if type(x) == str else 0)\n",
    "    lang_df = lang_df[lang_df['speech_length'] > 200]\n",
    "    filtered_speech_ids.update(lang_df.ID)\n",
    "    filtered_speeches[language] = lang_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T14:09:37.546374Z",
     "start_time": "2023-05-29T14:09:37.544380Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_speech_ids(speech2lemmas: dict[str, set[str]], keywords: set[str]):\n",
    "    for speech_id, lemmas in speech2lemmas.items():\n",
    "        speech_id = speech_id.replace('.ana', '')\n",
    "        if speech_id not in filtered_speech_ids:\n",
    "            continue\n",
    "        lemmas = lemmas.lower()\n",
    "        for keyword in keywords:\n",
    "            if keyword in lemmas:\n",
    "                yield speech_id\n",
    "                break\n",
    "\n",
    "\n",
    "def get_corpuses(topic_by_language: dict[str, set[str]]):\n",
    "    corpuses = {}\n",
    "    for language, speech2lemmas in speeches.items():\n",
    "        speech_ids = list(get_speech_ids(speech2lemmas, topic_by_language[language]))\n",
    "        corpuses[language] = speech_ids\n",
    "    return corpuses\n",
    "\n",
    "\n",
    "def print_corpuses(corpuses):\n",
    "    for lang, corpus in corpuses.items():\n",
    "        print(f'{lang}:', len(corpus))\n",
    "        print(corpus[:10])\n",
    "        print('-' * 40)\n",
    "\n",
    "\n",
    "def save_corpuses(topic, corpuses):\n",
    "    artefacts_dir = Path('artefacts/by_topic')\n",
    "    artefacts_dir.mkdir(exist_ok=True)\n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'common': set([t for l in corpuses.values() for t in l]),\n",
    "        **corpuses\n",
    "    }, orient='index').transpose()\n",
    "    df.to_feather(artefacts_dir / f'{topic}.feather')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T14:13:48.802648Z",
     "start_time": "2023-05-29T14:13:48.199039Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eu', 'war', 'healthcare', 'gender'])\n",
      "dict_keys(['UK', 'Hungary', 'Slovenian', 'Ukrainian'])\n",
      "['bataljon', 'bojen ladja', 'bojen letalo', 'brezpiloten', 'garda', 'genocid', 'genocid', 'invazija', 'kontingent', 'ljudski armada', 'mornarica', 'naborniški', 'oborožitev', 'obramben', 'oklepnik', 'orožje', 'pehota', 'poveljstvo', 'reparacija', 'rezervist', 'služenje vojaški', 'služenje vojen', 'strelen orožje', 'strelivo', 'tank', 'vojak', 'vojaški', 'vojaškoindustrijski', 'vojašnica', 'vojen', 'vojen taborišče', 'vojen ujetnik', 'vojna', 'vojska']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://docs.google.com/spreadsheets/d/1v7Kv1kVPWhBwGMDI6g2-pfanTfKuys8mmp1L0sMsMsM/export?format=csv&gid=0'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "topics = {}\n",
    "for column in df.columns:\n",
    "    theme, lang = column.split(' (')\n",
    "    theme = theme.split(': ')[1].lower()\n",
    "    lang = lang.rstrip(')')\n",
    "    if theme not in topics:\n",
    "        topics[theme] = {}\n",
    "    topics[theme][lang] = [i.lower() for i in df[column].tolist() if type(i) is str and i]\n",
    "\n",
    "print(topics.keys())\n",
    "print(topics['healthcare'].keys())\n",
    "print(topics['war']['Slovenian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T14:14:55.368990Z",
     "start_time": "2023-05-29T14:13:53.751486Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:01<00:00, 15.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>SI_count</th>\n",
       "      <th>SI_percentage</th>\n",
       "      <th>GB_count</th>\n",
       "      <th>GB_percentage</th>\n",
       "      <th>HU_count</th>\n",
       "      <th>HU_percentage</th>\n",
       "      <th>UA_count</th>\n",
       "      <th>UA_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu</td>\n",
       "      <td>21072</td>\n",
       "      <td>17.058204</td>\n",
       "      <td>64688</td>\n",
       "      <td>17.042802</td>\n",
       "      <td>8017</td>\n",
       "      <td>18.876854</td>\n",
       "      <td>9019</td>\n",
       "      <td>12.863153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>war</td>\n",
       "      <td>19141</td>\n",
       "      <td>15.495021</td>\n",
       "      <td>90611</td>\n",
       "      <td>23.872516</td>\n",
       "      <td>4971</td>\n",
       "      <td>11.704733</td>\n",
       "      <td>7045</td>\n",
       "      <td>10.047779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>healthcare</td>\n",
       "      <td>18776</td>\n",
       "      <td>15.199547</td>\n",
       "      <td>59433</td>\n",
       "      <td>15.658311</td>\n",
       "      <td>8044</td>\n",
       "      <td>18.940429</td>\n",
       "      <td>6027</td>\n",
       "      <td>8.595878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender</td>\n",
       "      <td>1312</td>\n",
       "      <td>1.062090</td>\n",
       "      <td>3943</td>\n",
       "      <td>1.038829</td>\n",
       "      <td>101</td>\n",
       "      <td>0.237815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic  SI_count  SI_percentage  GB_count  GB_percentage  HU_count  \\\n",
       "0          eu     21072      17.058204     64688      17.042802      8017   \n",
       "1         war     19141      15.495021     90611      23.872516      4971   \n",
       "2  healthcare     18776      15.199547     59433      15.658311      8044   \n",
       "3      gender      1312       1.062090      3943       1.038829       101   \n",
       "\n",
       "   HU_percentage  UA_count  UA_percentage  \n",
       "0      18.876854      9019      12.863153  \n",
       "1      11.704733      7045      10.047779  \n",
       "2      18.940429      6027       8.595878  \n",
       "3       0.237815         0       0.000000  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = []\n",
    "languages = {\n",
    "    'UK': Languages.gb,\n",
    "    'Hungary': Languages.hu,\n",
    "    'Slovenian': Languages.si,\n",
    "    'Ukrainian': Languages.ua,\n",
    "}\n",
    "for topic in tqdm(topics):\n",
    "    row_dict = {'topic': topic}\n",
    "    keywords = {}\n",
    "    for language in topics[topic]:\n",
    "        keywords[languages[language]] = set(topics[topic][language])\n",
    "    healthcare = save_corpuses(topic, get_corpuses(keywords))\n",
    "    healthcare_count = healthcare.count().to_dict()\n",
    "    for lang, count in healthcare_count.items():\n",
    "        if lang not in Languages.all:\n",
    "            continue\n",
    "        percentage = 100 * count / len(filtered_speeches[lang])\n",
    "        row_dict[f'{lang}_count'] = count\n",
    "        row_dict[f'{lang}_percentage'] = percentage\n",
    "    df_data.append(row_dict)\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
